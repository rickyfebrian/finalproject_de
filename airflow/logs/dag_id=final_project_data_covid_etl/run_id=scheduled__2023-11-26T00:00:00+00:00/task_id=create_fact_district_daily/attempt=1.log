[2023-11-27 07:13:24,887] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 07:13:24,897] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 07:13:24,897] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 07:13:24,898] {taskinstance.py:1357} INFO - Starting attempt 1 of 3
[2023-11-27 07:13:24,898] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 07:13:24,915] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_fact_district_daily> on 2023-11-26 00:00:00+00:00
[2023-11-27 07:13:24,920] {standard_task_runner.py:52} INFO - Started process 228 to run task
[2023-11-27 07:13:24,923] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'final_project_data_covid_etl', 'create_fact_district_daily', 'scheduled__2023-11-26T00:00:00+00:00', '--job-id', '338', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmp_i9dnkel', '--error-file', '/tmp/tmph75fr89l']
[2023-11-27 07:13:24,923] {standard_task_runner.py:80} INFO - Job 338: Subtask create_fact_district_daily
[2023-11-27 07:13:24,972] {task_command.py:369} INFO - Running <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [running]> on host 671693f20ed3
[2023-11-27 07:13:25,043] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=ricky
AIRFLOW_CTX_DAG_ID=final_project_data_covid_etl
AIRFLOW_CTX_TASK_ID=create_fact_district_daily
AIRFLOW_CTX_EXECUTION_DATE=2023-11-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-26T00:00:00+00:00
[2023-11-27 07:13:25,044] {python.py:173} INFO - Done. Returned value was: None
[2023-11-27 07:13:25,055] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=final_project_data_covid_etl, task_id=create_fact_district_daily, execution_date=20231126T000000, start_date=20231127T071324, end_date=20231127T071325
[2023-11-27 07:13:25,095] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-11-27 07:13:25,132] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-11-27 07:20:00,567] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 07:20:00,578] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 07:20:00,578] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 07:20:00,578] {taskinstance.py:1357} INFO - Starting attempt 1 of 3
[2023-11-27 07:20:00,578] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 07:20:00,594] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_fact_district_daily> on 2023-11-26 00:00:00+00:00
[2023-11-27 07:20:00,598] {standard_task_runner.py:52} INFO - Started process 376 to run task
[2023-11-27 07:20:00,602] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'final_project_data_covid_etl', 'create_fact_district_daily', 'scheduled__2023-11-26T00:00:00+00:00', '--job-id', '355', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmprcvcn75p', '--error-file', '/tmp/tmpqz8d41am']
[2023-11-27 07:20:00,604] {standard_task_runner.py:80} INFO - Job 355: Subtask create_fact_district_daily
[2023-11-27 07:20:00,671] {task_command.py:369} INFO - Running <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [running]> on host 671693f20ed3
[2023-11-27 07:20:00,752] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=ricky
AIRFLOW_CTX_DAG_ID=final_project_data_covid_etl
AIRFLOW_CTX_TASK_ID=create_fact_district_daily
AIRFLOW_CTX_EXECUTION_DATE=2023-11-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-26T00:00:00+00:00
[2023-11-27 07:20:00,753] {python.py:173} INFO - Done. Returned value was: None
[2023-11-27 07:20:00,764] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=final_project_data_covid_etl, task_id=create_fact_district_daily, execution_date=20231126T000000, start_date=20231127T072000, end_date=20231127T072000
[2023-11-27 07:20:00,813] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-11-27 07:20:00,870] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-11-27 09:18:59,093] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 09:18:59,103] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 09:18:59,103] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 09:18:59,103] {taskinstance.py:1357} INFO - Starting attempt 1 of 3
[2023-11-27 09:18:59,103] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 09:18:59,119] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_fact_district_daily> on 2023-11-26 00:00:00+00:00
[2023-11-27 09:18:59,124] {standard_task_runner.py:52} INFO - Started process 400 to run task
[2023-11-27 09:18:59,127] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'final_project_data_covid_etl', 'create_fact_district_daily', 'scheduled__2023-11-26T00:00:00+00:00', '--job-id', '372', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmp_0hsuryp', '--error-file', '/tmp/tmpzuczbvkp']
[2023-11-27 09:18:59,128] {standard_task_runner.py:80} INFO - Job 372: Subtask create_fact_district_daily
[2023-11-27 09:18:59,203] {task_command.py:369} INFO - Running <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [running]> on host f38c0c12695c
[2023-11-27 09:18:59,298] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=ricky
AIRFLOW_CTX_DAG_ID=final_project_data_covid_etl
AIRFLOW_CTX_TASK_ID=create_fact_district_daily
AIRFLOW_CTX_EXECUTION_DATE=2023-11-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-26T00:00:00+00:00
[2023-11-27 09:18:59,299] {python.py:173} INFO - Done. Returned value was: None
[2023-11-27 09:18:59,316] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=final_project_data_covid_etl, task_id=create_fact_district_daily, execution_date=20231126T000000, start_date=20231127T091859, end_date=20231127T091859
[2023-11-27 09:18:59,338] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-11-27 09:18:59,376] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-11-27 09:27:28,779] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 09:27:28,789] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 09:27:28,789] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 09:27:28,789] {taskinstance.py:1357} INFO - Starting attempt 1 of 3
[2023-11-27 09:27:28,789] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 09:27:28,805] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_fact_district_daily> on 2023-11-26 00:00:00+00:00
[2023-11-27 09:27:28,811] {standard_task_runner.py:52} INFO - Started process 669 to run task
[2023-11-27 09:27:28,814] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'final_project_data_covid_etl', 'create_fact_district_daily', 'scheduled__2023-11-26T00:00:00+00:00', '--job-id', '389', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmp04hsuui9', '--error-file', '/tmp/tmphgm4w3fq']
[2023-11-27 09:27:28,815] {standard_task_runner.py:80} INFO - Job 389: Subtask create_fact_district_daily
[2023-11-27 09:27:28,865] {task_command.py:369} INFO - Running <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [running]> on host f38c0c12695c
[2023-11-27 09:27:28,935] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=ricky
AIRFLOW_CTX_DAG_ID=final_project_data_covid_etl
AIRFLOW_CTX_TASK_ID=create_fact_district_daily
AIRFLOW_CTX_EXECUTION_DATE=2023-11-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-26T00:00:00+00:00
[2023-11-27 09:27:28,936] {python.py:173} INFO - Done. Returned value was: None
[2023-11-27 09:27:28,950] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=final_project_data_covid_etl, task_id=create_fact_district_daily, execution_date=20231126T000000, start_date=20231127T092728, end_date=20231127T092728
[2023-11-27 09:27:28,985] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-11-27 09:27:29,020] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-11-27 14:12:35,461] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 14:12:35,480] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 14:12:35,480] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 14:12:35,480] {taskinstance.py:1357} INFO - Starting attempt 1 of 3
[2023-11-27 14:12:35,480] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 14:12:35,501] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_fact_district_daily> on 2023-11-26 00:00:00+00:00
[2023-11-27 14:12:35,506] {standard_task_runner.py:52} INFO - Started process 550 to run task
[2023-11-27 14:12:35,510] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'final_project_data_covid_etl', 'create_fact_district_daily', 'scheduled__2023-11-26T00:00:00+00:00', '--job-id', '441', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmpylkk13mf', '--error-file', '/tmp/tmpu5h0_u27']
[2023-11-27 14:12:35,511] {standard_task_runner.py:80} INFO - Job 441: Subtask create_fact_district_daily
[2023-11-27 14:12:35,578] {task_command.py:369} INFO - Running <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [running]> on host 9bd194bc0dbc
[2023-11-27 14:12:35,653] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=ricky
AIRFLOW_CTX_DAG_ID=final_project_data_covid_etl
AIRFLOW_CTX_TASK_ID=create_fact_district_daily
AIRFLOW_CTX_EXECUTION_DATE=2023-11-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-26T00:00:00+00:00
[2023-11-27 14:12:35,696] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1194, in execute
    meth = statement._execute_on_connection
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 5487, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'DataFrame' object has no attribute '_execute_on_connection'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/get_data.py", line 92, in create_fact_district_daily
    df = pd.read_sql_query(sql_query, engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 443, in read_sql_query
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1579, in read_query
    result = self.execute(*args)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1424, in execute
    return self.connectable.execution_options().execute(*args, **kwargs)
  File "<string>", line 2, in execute
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py", line 390, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3037, in execute
    return connection.execute(statement, *multiparams, **params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1197, in execute
    exc.ObjectNotExecutableError(statement), replace_context=err
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
sqlalchemy.exc.ObjectNotExecutableError: Not an executable object:      CLOSECONTACT  CONFIRMATION  ...  suspect_meninggal     tanggal
0             274             0  ...                  0  2020-08-05
1             534             0  ...                  0  2020-08-05
2            2127             0  ...                  0  2020-08-05
3               0             0  ...                  0  2020-08-05
4            1295             0  ...                  0  2020-08-05
..            ...           ...  ...                ...         ...
140            32             0  ...                  2  2020-08-10
141             0             0  ...                  0  2020-08-10
142             0             2  ...                  0  2020-08-10
143            12             0  ...                  0  2020-08-10
144            28             1  ...                  0  2020-08-10

[145 rows x 20 columns]
[2023-11-27 14:12:35,705] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=final_project_data_covid_etl, task_id=create_fact_district_daily, execution_date=20231126T000000, start_date=20231127T141235, end_date=20231127T141235
[2023-11-27 14:12:35,720] {standard_task_runner.py:97} ERROR - Failed to execute job 441 for task create_fact_district_daily (Not an executable object:      CLOSECONTACT  CONFIRMATION  ...  suspect_meninggal     tanggal
0             274             0  ...                  0  2020-08-05
1             534             0  ...                  0  2020-08-05
2            2127             0  ...                  0  2020-08-05
3               0             0  ...                  0  2020-08-05
4            1295             0  ...                  0  2020-08-05
..            ...           ...  ...                ...         ...
140            32             0  ...                  2  2020-08-10
141             0             0  ...                  0  2020-08-10
142             0             2  ...                  0  2020-08-10
143            12             0  ...                  0  2020-08-10
144            28             1  ...                  0  2020-08-10

[145 rows x 20 columns]; 550)
[2023-11-27 14:12:35,764] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-11-27 14:12:35,802] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-11-27 14:23:28,182] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 14:23:28,192] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [queued]>
[2023-11-27 14:23:28,192] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 14:23:28,192] {taskinstance.py:1357} INFO - Starting attempt 1 of 3
[2023-11-27 14:23:28,192] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-27 14:23:28,208] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_fact_district_daily> on 2023-11-26 00:00:00+00:00
[2023-11-27 14:23:28,212] {standard_task_runner.py:52} INFO - Started process 894 to run task
[2023-11-27 14:23:28,216] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'final_project_data_covid_etl', 'create_fact_district_daily', 'scheduled__2023-11-26T00:00:00+00:00', '--job-id', '461', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmpd1ih53za', '--error-file', '/tmp/tmpopo6_qqh']
[2023-11-27 14:23:28,217] {standard_task_runner.py:80} INFO - Job 461: Subtask create_fact_district_daily
[2023-11-27 14:23:28,270] {task_command.py:369} INFO - Running <TaskInstance: final_project_data_covid_etl.create_fact_district_daily scheduled__2023-11-26T00:00:00+00:00 [running]> on host 9bd194bc0dbc
[2023-11-27 14:23:28,349] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=ricky
AIRFLOW_CTX_DAG_ID=final_project_data_covid_etl
AIRFLOW_CTX_TASK_ID=create_fact_district_daily
AIRFLOW_CTX_EXECUTION_DATE=2023-11-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-26T00:00:00+00:00
[2023-11-27 14:23:28,389] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1194, in execute
    meth = statement._execute_on_connection
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 5487, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'DataFrame' object has no attribute '_execute_on_connection'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/get_data.py", line 93, in create_fact_district_daily
    df = pd.read_sql_query(sql_query, engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 443, in read_sql_query
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1579, in read_query
    result = self.execute(*args)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1424, in execute
    return self.connectable.execution_options().execute(*args, **kwargs)
  File "<string>", line 2, in execute
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py", line 390, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3037, in execute
    return connection.execute(statement, *multiparams, **params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1197, in execute
    exc.ObjectNotExecutableError(statement), replace_context=err
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
sqlalchemy.exc.ObjectNotExecutableError: Not an executable object:      CLOSECONTACT  CONFIRMATION  ...  suspect_meninggal     tanggal
0             274             0  ...                  0  2020-08-05
1             534             0  ...                  0  2020-08-05
2            2127             0  ...                  0  2020-08-05
3               0             0  ...                  0  2020-08-05
4            1295             0  ...                  0  2020-08-05
..            ...           ...  ...                ...         ...
140            32             0  ...                  2  2020-08-10
141             0             0  ...                  0  2020-08-10
142             0             2  ...                  0  2020-08-10
143            12             0  ...                  0  2020-08-10
144            28             1  ...                  0  2020-08-10

[145 rows x 20 columns]
[2023-11-27 14:23:28,402] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=final_project_data_covid_etl, task_id=create_fact_district_daily, execution_date=20231126T000000, start_date=20231127T142328, end_date=20231127T142328
[2023-11-27 14:23:28,413] {standard_task_runner.py:97} ERROR - Failed to execute job 461 for task create_fact_district_daily (Not an executable object:      CLOSECONTACT  CONFIRMATION  ...  suspect_meninggal     tanggal
0             274             0  ...                  0  2020-08-05
1             534             0  ...                  0  2020-08-05
2            2127             0  ...                  0  2020-08-05
3               0             0  ...                  0  2020-08-05
4            1295             0  ...                  0  2020-08-05
..            ...           ...  ...                ...         ...
140            32             0  ...                  2  2020-08-10
141             0             0  ...                  0  2020-08-10
142             0             2  ...                  0  2020-08-10
143            12             0  ...                  0  2020-08-10
144            28             1  ...                  0  2020-08-10

[145 rows x 20 columns]; 894)
[2023-11-27 14:23:28,427] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-11-27 14:23:28,469] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
