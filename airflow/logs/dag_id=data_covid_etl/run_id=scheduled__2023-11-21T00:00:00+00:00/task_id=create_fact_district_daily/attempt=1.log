[2023-11-26 15:39:36,907] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [queued]>
[2023-11-26 15:39:36,958] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [queued]>
[2023-11-26 15:39:36,958] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 15:39:36,958] {taskinstance.py:1357} INFO - Starting attempt 1 of 6
[2023-11-26 15:39:36,958] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 15:39:37,035] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_fact_district_daily> on 2023-11-21 00:00:00+00:00
[2023-11-26 15:39:37,050] {standard_task_runner.py:52} INFO - Started process 2537 to run task
[2023-11-26 15:39:37,063] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_covid_etl', 'create_fact_district_daily', 'scheduled__2023-11-21T00:00:00+00:00', '--job-id', '49', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmpvu4i0wnv', '--error-file', '/tmp/tmpsas9avk4']
[2023-11-26 15:39:37,064] {standard_task_runner.py:80} INFO - Job 49: Subtask create_fact_district_daily
[2023-11-26 15:39:37,220] {task_command.py:369} INFO - Running <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [running]> on host f384f2afcc4f
[2023-11-26 15:39:37,514] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=oce
AIRFLOW_CTX_DAG_ID=data_covid_etl
AIRFLOW_CTX_TASK_ID=create_fact_district_daily
AIRFLOW_CTX_EXECUTION_DATE=2023-11-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-21T00:00:00+00:00
[2023-11-26 15:39:37,514] {python.py:173} INFO - Done. Returned value was: None
[2023-11-26 15:39:37,544] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=data_covid_etl, task_id=create_fact_district_daily, execution_date=20231121T000000, start_date=20231126T153936, end_date=20231126T153937
[2023-11-26 15:39:37,572] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-11-26 15:39:37,648] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-11-26 17:57:09,432] {taskinstance.py:1153} INFO - Dependencies not met for <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [queued]>, dependency 'Trigger Rule' FAILED: Task's trigger rule 'all_success' requires all upstream tasks to have succeeded, but found 1 non-success(es). upstream_tasks_state={'total': 1, 'successes': 0, 'skipped': 0, 'failed': 0, 'upstream_failed': 0, 'done': 0}, upstream_task_ids={'create_dim_case'}
[2023-11-26 17:57:09,454] {local_task_job.py:101} INFO - Task is not able to be run
[2023-11-26 18:06:12,928] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [queued]>
[2023-11-26 18:06:12,938] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [queued]>
[2023-11-26 18:06:12,938] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:06:12,938] {taskinstance.py:1357} INFO - Starting attempt 1 of 3
[2023-11-26 18:06:12,938] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:06:12,954] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_fact_district_daily> on 2023-11-21 00:00:00+00:00
[2023-11-26 18:06:12,959] {standard_task_runner.py:52} INFO - Started process 1209 to run task
[2023-11-26 18:06:12,962] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_covid_etl', 'create_fact_district_daily', 'scheduled__2023-11-21T00:00:00+00:00', '--job-id', '208', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmpprgvfhn6', '--error-file', '/tmp/tmpiwnog85t']
[2023-11-26 18:06:12,963] {standard_task_runner.py:80} INFO - Job 208: Subtask create_fact_district_daily
[2023-11-26 18:06:13,037] {task_command.py:369} INFO - Running <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [running]> on host 79a606f4be36
[2023-11-26 18:06:13,102] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=oce
AIRFLOW_CTX_DAG_ID=data_covid_etl
AIRFLOW_CTX_TASK_ID=create_fact_district_daily
AIRFLOW_CTX_EXECUTION_DATE=2023-11-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-21T00:00:00+00:00
[2023-11-26 18:06:13,103] {python.py:173} INFO - Done. Returned value was: None
[2023-11-26 18:06:13,117] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=data_covid_etl, task_id=create_fact_district_daily, execution_date=20231121T000000, start_date=20231126T180612, end_date=20231126T180613
[2023-11-26 18:06:13,134] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-11-26 18:06:13,182] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-11-26 18:13:54,170] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [queued]>
[2023-11-26 18:13:54,183] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [queued]>
[2023-11-26 18:13:54,184] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:13:54,184] {taskinstance.py:1357} INFO - Starting attempt 1 of 3
[2023-11-26 18:13:54,184] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:13:54,205] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_fact_district_daily> on 2023-11-21 00:00:00+00:00
[2023-11-26 18:13:54,211] {standard_task_runner.py:52} INFO - Started process 1539 to run task
[2023-11-26 18:13:54,214] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_covid_etl', 'create_fact_district_daily', 'scheduled__2023-11-21T00:00:00+00:00', '--job-id', '247', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmpepu0y4b7', '--error-file', '/tmp/tmpa87xklo8']
[2023-11-26 18:13:54,215] {standard_task_runner.py:80} INFO - Job 247: Subtask create_fact_district_daily
[2023-11-26 18:13:54,272] {task_command.py:369} INFO - Running <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [running]> on host 79a606f4be36
[2023-11-26 18:13:54,361] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=oce
AIRFLOW_CTX_DAG_ID=data_covid_etl
AIRFLOW_CTX_TASK_ID=create_fact_district_daily
AIRFLOW_CTX_EXECUTION_DATE=2023-11-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-21T00:00:00+00:00
[2023-11-26 18:13:54,362] {python.py:173} INFO - Done. Returned value was: None
[2023-11-26 18:13:54,389] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=data_covid_etl, task_id=create_fact_district_daily, execution_date=20231121T000000, start_date=20231126T181354, end_date=20231126T181354
[2023-11-26 18:13:54,430] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-11-26 18:13:54,471] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-11-26 18:15:30,412] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [queued]>
[2023-11-26 18:15:30,422] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [queued]>
[2023-11-26 18:15:30,422] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:15:30,422] {taskinstance.py:1357} INFO - Starting attempt 1 of 3
[2023-11-26 18:15:30,422] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:15:30,436] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_fact_district_daily> on 2023-11-21 00:00:00+00:00
[2023-11-26 18:15:30,441] {standard_task_runner.py:52} INFO - Started process 1649 to run task
[2023-11-26 18:15:30,444] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_covid_etl', 'create_fact_district_daily', 'scheduled__2023-11-21T00:00:00+00:00', '--job-id', '270', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmpkpreg9iw', '--error-file', '/tmp/tmpvulc4nry']
[2023-11-26 18:15:30,444] {standard_task_runner.py:80} INFO - Job 270: Subtask create_fact_district_daily
[2023-11-26 18:15:30,492] {task_command.py:369} INFO - Running <TaskInstance: data_covid_etl.create_fact_district_daily scheduled__2023-11-21T00:00:00+00:00 [running]> on host 79a606f4be36
[2023-11-26 18:15:30,556] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=oce
AIRFLOW_CTX_DAG_ID=data_covid_etl
AIRFLOW_CTX_TASK_ID=create_fact_district_daily
AIRFLOW_CTX_EXECUTION_DATE=2023-11-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-21T00:00:00+00:00
[2023-11-26 18:15:30,556] {python.py:173} INFO - Done. Returned value was: None
[2023-11-26 18:15:30,566] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=data_covid_etl, task_id=create_fact_district_daily, execution_date=20231121T000000, start_date=20231126T181530, end_date=20231126T181530
[2023-11-26 18:15:30,616] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-11-26 18:15:30,653] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
