[2023-11-26 15:39:40,259] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 15:39:40,282] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 15:39:40,285] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 15:39:40,285] {taskinstance.py:1357} INFO - Starting attempt 1 of 6
[2023-11-26 15:39:40,286] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 15:39:40,337] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_dim_province> on 2023-11-24 00:00:00+00:00
[2023-11-26 15:39:40,345] {standard_task_runner.py:52} INFO - Started process 2582 to run task
[2023-11-26 15:39:40,372] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_covid_etl', 'create_dim_province', 'scheduled__2023-11-24T00:00:00+00:00', '--job-id', '68', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmph0tl74n0', '--error-file', '/tmp/tmpjdyqisyp']
[2023-11-26 15:39:40,376] {standard_task_runner.py:80} INFO - Job 68: Subtask create_dim_province
[2023-11-26 15:39:40,536] {task_command.py:369} INFO - Running <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [running]> on host f384f2afcc4f
[2023-11-26 15:39:40,785] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=oce
AIRFLOW_CTX_DAG_ID=data_covid_etl
AIRFLOW_CTX_TASK_ID=create_dim_province
AIRFLOW_CTX_EXECUTION_DATE=2023-11-24T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-24T00:00:00+00:00
[2023-11-26 15:39:40,787] {python.py:173} INFO - Done. Returned value was: None
[2023-11-26 15:39:40,812] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=data_covid_etl, task_id=create_dim_province, execution_date=20231124T000000, start_date=20231126T153940, end_date=20231126T153940
[2023-11-26 15:39:40,861] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-11-26 15:39:40,927] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-11-26 17:57:47,868] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 17:57:47,878] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 17:57:47,878] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 17:57:47,878] {taskinstance.py:1357} INFO - Starting attempt 1 of 6
[2023-11-26 17:57:47,878] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 17:57:47,896] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_dim_province> on 2023-11-24 00:00:00+00:00
[2023-11-26 17:57:47,901] {standard_task_runner.py:52} INFO - Started process 756 to run task
[2023-11-26 17:57:47,904] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_covid_etl', 'create_dim_province', 'scheduled__2023-11-24T00:00:00+00:00', '--job-id', '134', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmpmujzfl7d', '--error-file', '/tmp/tmp7xkwjfdo']
[2023-11-26 17:57:47,905] {standard_task_runner.py:80} INFO - Job 134: Subtask create_dim_province
[2023-11-26 17:57:47,964] {task_command.py:369} INFO - Running <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [running]> on host 79a606f4be36
[2023-11-26 17:57:48,041] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=oce
AIRFLOW_CTX_DAG_ID=data_covid_etl
AIRFLOW_CTX_TASK_ID=create_dim_province
AIRFLOW_CTX_EXECUTION_DATE=2023-11-24T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-24T00:00:00+00:00
[2023-11-26 17:57:48,042] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/get_data.py", line 38, in create_dim_province
    engine = create_engine(staging_db_constring)
NameError: name 'create_engine' is not defined
[2023-11-26 17:57:48,053] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=data_covid_etl, task_id=create_dim_province, execution_date=20231124T000000, start_date=20231126T175747, end_date=20231126T175748
[2023-11-26 17:57:48,067] {standard_task_runner.py:97} ERROR - Failed to execute job 134 for task create_dim_province (name 'create_engine' is not defined; 756)
[2023-11-26 17:57:48,076] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-11-26 17:57:48,114] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-11-26 18:00:56,040] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 18:00:56,050] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 18:00:56,050] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:00:56,050] {taskinstance.py:1357} INFO - Starting attempt 1 of 6
[2023-11-26 18:00:56,050] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:00:56,063] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_dim_province> on 2023-11-24 00:00:00+00:00
[2023-11-26 18:00:56,070] {standard_task_runner.py:52} INFO - Started process 930 to run task
[2023-11-26 18:00:56,075] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_covid_etl', 'create_dim_province', 'scheduled__2023-11-24T00:00:00+00:00', '--job-id', '161', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmpsg3q0dj8', '--error-file', '/tmp/tmp3tny2kfu']
[2023-11-26 18:00:56,075] {standard_task_runner.py:80} INFO - Job 161: Subtask create_dim_province
[2023-11-26 18:00:56,124] {task_command.py:369} INFO - Running <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [running]> on host 79a606f4be36
[2023-11-26 18:00:56,206] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=oce
AIRFLOW_CTX_DAG_ID=data_covid_etl
AIRFLOW_CTX_TASK_ID=create_dim_province
AIRFLOW_CTX_EXECUTION_DATE=2023-11-24T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-24T00:00:00+00:00
[2023-11-26 18:00:56,231] {python.py:173} INFO - Done. Returned value was:     province_id province_name
0            32    Jawa Barat
1            32    Jawa Barat
2            32    Jawa Barat
3            32    Jawa Barat
4            32    Jawa Barat
..          ...           ...
140          32    Jawa Barat
141          32    Jawa Barat
142          32    Jawa Barat
143          32    Jawa Barat
144          32    Jawa Barat

[145 rows x 2 columns]
[2023-11-26 18:00:56,245] {xcom.py:585} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config.
[2023-11-26 18:00:56,246] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2380, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 197, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 582, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/local/lib/python3.7/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-11-26 18:00:56,254] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=data_covid_etl, task_id=create_dim_province, execution_date=20231124T000000, start_date=20231126T180056, end_date=20231126T180056
[2023-11-26 18:00:56,267] {standard_task_runner.py:97} ERROR - Failed to execute job 161 for task create_dim_province (Object of type DataFrame is not JSON serializable; 930)
[2023-11-26 18:00:56,288] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-11-26 18:00:56,330] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-11-26 18:02:43,736] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 18:02:43,747] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 18:02:43,747] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:02:43,747] {taskinstance.py:1357} INFO - Starting attempt 1 of 4
[2023-11-26 18:02:43,747] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:02:43,762] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_dim_province> on 2023-11-24 00:00:00+00:00
[2023-11-26 18:02:43,766] {standard_task_runner.py:52} INFO - Started process 1034 to run task
[2023-11-26 18:02:43,770] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_covid_etl', 'create_dim_province', 'scheduled__2023-11-24T00:00:00+00:00', '--job-id', '178', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmpwsgv1ats', '--error-file', '/tmp/tmpxd75qux1']
[2023-11-26 18:02:43,771] {standard_task_runner.py:80} INFO - Job 178: Subtask create_dim_province
[2023-11-26 18:02:43,836] {task_command.py:369} INFO - Running <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [running]> on host 79a606f4be36
[2023-11-26 18:02:43,910] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=oce
AIRFLOW_CTX_DAG_ID=data_covid_etl
AIRFLOW_CTX_TASK_ID=create_dim_province
AIRFLOW_CTX_EXECUTION_DATE=2023-11-24T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-24T00:00:00+00:00
[2023-11-26 18:02:43,930] {python.py:173} INFO - Done. Returned value was:     province_id province_name
0            32    Jawa Barat
1            32    Jawa Barat
2            32    Jawa Barat
3            32    Jawa Barat
4            32    Jawa Barat
..          ...           ...
140          32    Jawa Barat
141          32    Jawa Barat
142          32    Jawa Barat
143          32    Jawa Barat
144          32    Jawa Barat

[145 rows x 2 columns]
[2023-11-26 18:02:43,941] {xcom.py:585} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config.
[2023-11-26 18:02:43,942] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2380, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 197, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 582, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/local/lib/python3.7/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-11-26 18:02:43,948] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=data_covid_etl, task_id=create_dim_province, execution_date=20231124T000000, start_date=20231126T180243, end_date=20231126T180243
[2023-11-26 18:02:43,960] {standard_task_runner.py:97} ERROR - Failed to execute job 178 for task create_dim_province (Object of type DataFrame is not JSON serializable; 1034)
[2023-11-26 18:02:43,981] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-11-26 18:02:44,023] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-11-26 18:05:37,270] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 18:05:37,282] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 18:05:37,282] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:05:37,283] {taskinstance.py:1357} INFO - Starting attempt 1 of 3
[2023-11-26 18:05:37,283] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:05:37,302] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_dim_province> on 2023-11-24 00:00:00+00:00
[2023-11-26 18:05:37,308] {standard_task_runner.py:52} INFO - Started process 1161 to run task
[2023-11-26 18:05:37,310] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_covid_etl', 'create_dim_province', 'scheduled__2023-11-24T00:00:00+00:00', '--job-id', '196', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmpsorr02hn', '--error-file', '/tmp/tmpa1qs5v_k']
[2023-11-26 18:05:37,311] {standard_task_runner.py:80} INFO - Job 196: Subtask create_dim_province
[2023-11-26 18:05:37,358] {task_command.py:369} INFO - Running <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [running]> on host 79a606f4be36
[2023-11-26 18:05:37,430] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=oce
AIRFLOW_CTX_DAG_ID=data_covid_etl
AIRFLOW_CTX_TASK_ID=create_dim_province
AIRFLOW_CTX_EXECUTION_DATE=2023-11-24T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-24T00:00:00+00:00
[2023-11-26 18:05:37,454] {logging_mixin.py:115} INFO - province_id province_name
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
[2023-11-26 18:05:37,454] {python.py:173} INFO - Done. Returned value was: None
[2023-11-26 18:05:37,466] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=data_covid_etl, task_id=create_dim_province, execution_date=20231124T000000, start_date=20231126T180537, end_date=20231126T180537
[2023-11-26 18:05:37,483] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-11-26 18:05:37,524] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-11-26 18:08:48,649] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 18:08:48,659] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [queued]>
[2023-11-26 18:08:48,659] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:08:48,659] {taskinstance.py:1357} INFO - Starting attempt 1 of 3
[2023-11-26 18:08:48,659] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-11-26 18:08:48,674] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): create_dim_province> on 2023-11-24 00:00:00+00:00
[2023-11-26 18:08:48,679] {standard_task_runner.py:52} INFO - Started process 1342 to run task
[2023-11-26 18:08:48,683] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_covid_etl', 'create_dim_province', 'scheduled__2023-11-24T00:00:00+00:00', '--job-id', '226', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmpaedgo027', '--error-file', '/tmp/tmpawpaiz1x']
[2023-11-26 18:08:48,684] {standard_task_runner.py:80} INFO - Job 226: Subtask create_dim_province
[2023-11-26 18:08:48,733] {task_command.py:369} INFO - Running <TaskInstance: data_covid_etl.create_dim_province scheduled__2023-11-24T00:00:00+00:00 [running]> on host 79a606f4be36
[2023-11-26 18:08:48,810] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=oce
AIRFLOW_CTX_DAG_ID=data_covid_etl
AIRFLOW_CTX_TASK_ID=create_dim_province
AIRFLOW_CTX_EXECUTION_DATE=2023-11-24T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-24T00:00:00+00:00
[2023-11-26 18:08:48,834] {logging_mixin.py:115} INFO - province_id province_name
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
         32    Jawa Barat
[2023-11-26 18:08:48,837] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "digiskola-postgresql-db-1" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/get_data.py", line 46, in create_dim_province
    df.to_sql('dim_province', engine_postgres, index=False, if_exists='replace')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1758, in to_sql
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1650, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 856, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 840, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1783, in has_table
    insp = sa.inspect(self.connectable)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/inspection.py", line 64, in inspect
    ret = reg(subject)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/reflection.py", line 182, in _engine_insp
    return Inspector._construct(Inspector._init_engine, bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/reflection.py", line 117, in _construct
    init(self, bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/reflection.py", line 128, in _init_engine
    engine.connect().close()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 142, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "digiskola-postgresql-db-1" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2023-11-26 18:08:48,848] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=data_covid_etl, task_id=create_dim_province, execution_date=20231124T000000, start_date=20231126T180848, end_date=20231126T180848
[2023-11-26 18:08:48,862] {standard_task_runner.py:97} ERROR - Failed to execute job 226 for task create_dim_province ((psycopg2.OperationalError) could not translate host name "digiskola-postgresql-db-1" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8); 1342)
[2023-11-26 18:08:48,895] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-11-26 18:08:48,933] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
